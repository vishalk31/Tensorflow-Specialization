{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90207da8",
   "metadata": {},
   "source": [
    "# Importing packages and Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28859678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39de543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pricing = pd.read_csv(\"train.csv\")\n",
    "df_pricing_test = pd.read_csv('test.csv')\n",
    "output = df_pricing[\"SalePrice\"]\n",
    "df_pricing_one = pd.concat([df_pricing,df_pricing_test],axis=0,sort=False)\n",
    "df_pricing_one.drop([\"SalePrice\"],axis = 1,inplace =True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eb29a7",
   "metadata": {},
   "source": [
    "# ***Identifying Missing Values***\n",
    "code below will give us the missing value count with percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4323c3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Number of Missing Values</th>\n",
       "      <th>Percentage of Missing Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PoolQC</td>\n",
       "      <td>2909</td>\n",
       "      <td>99.657417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MiscFeature</td>\n",
       "      <td>2814</td>\n",
       "      <td>96.402878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alley</td>\n",
       "      <td>2721</td>\n",
       "      <td>93.216855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fence</td>\n",
       "      <td>2348</td>\n",
       "      <td>80.438506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FireplaceQu</td>\n",
       "      <td>1420</td>\n",
       "      <td>48.646797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LotFrontage</td>\n",
       "      <td>486</td>\n",
       "      <td>16.649538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>159</td>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GarageQual</td>\n",
       "      <td>159</td>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GarageCond</td>\n",
       "      <td>159</td>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>159</td>\n",
       "      <td>5.447071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GarageType</td>\n",
       "      <td>157</td>\n",
       "      <td>5.378554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BsmtExposure</td>\n",
       "      <td>82</td>\n",
       "      <td>2.809181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BsmtCond</td>\n",
       "      <td>82</td>\n",
       "      <td>2.809181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>81</td>\n",
       "      <td>2.774923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BsmtFinType2</td>\n",
       "      <td>80</td>\n",
       "      <td>2.740665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BsmtFinType1</td>\n",
       "      <td>79</td>\n",
       "      <td>2.706406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MasVnrType</td>\n",
       "      <td>24</td>\n",
       "      <td>0.822199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MasVnrArea</td>\n",
       "      <td>23</td>\n",
       "      <td>0.787941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MSZoning</td>\n",
       "      <td>4</td>\n",
       "      <td>0.137033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BsmtFullBath</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BsmtHalfBath</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Functional</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GarageArea</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GarageCars</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Electrical</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TotalBsmtSF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BsmtUnfSF</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BsmtFinSF2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>BsmtFinSF1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Exterior2nd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Exterior1st</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SaleType</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature  Number of Missing Values  Percentage of Missing Values\n",
       "0         PoolQC                      2909                     99.657417\n",
       "1    MiscFeature                      2814                     96.402878\n",
       "2          Alley                      2721                     93.216855\n",
       "3          Fence                      2348                     80.438506\n",
       "4    FireplaceQu                      1420                     48.646797\n",
       "5    LotFrontage                       486                     16.649538\n",
       "6   GarageFinish                       159                      5.447071\n",
       "7     GarageQual                       159                      5.447071\n",
       "8     GarageCond                       159                      5.447071\n",
       "9    GarageYrBlt                       159                      5.447071\n",
       "10    GarageType                       157                      5.378554\n",
       "11  BsmtExposure                        82                      2.809181\n",
       "12      BsmtCond                        82                      2.809181\n",
       "13      BsmtQual                        81                      2.774923\n",
       "14  BsmtFinType2                        80                      2.740665\n",
       "15  BsmtFinType1                        79                      2.706406\n",
       "16    MasVnrType                        24                      0.822199\n",
       "17    MasVnrArea                        23                      0.787941\n",
       "18      MSZoning                         4                      0.137033\n",
       "19  BsmtFullBath                         2                      0.068517\n",
       "20  BsmtHalfBath                         2                      0.068517\n",
       "21    Functional                         2                      0.068517\n",
       "22     Utilities                         2                      0.068517\n",
       "23    GarageArea                         1                      0.034258\n",
       "24    GarageCars                         1                      0.034258\n",
       "25    Electrical                         1                      0.034258\n",
       "26   KitchenQual                         1                      0.034258\n",
       "27   TotalBsmtSF                         1                      0.034258\n",
       "28     BsmtUnfSF                         1                      0.034258\n",
       "29    BsmtFinSF2                         1                      0.034258\n",
       "30    BsmtFinSF1                         1                      0.034258\n",
       "31   Exterior2nd                         1                      0.034258\n",
       "32   Exterior1st                         1                      0.034258\n",
       "33      SaleType                         1                      0.034258"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = df_pricing_one.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending = False)\n",
    "NAN_col = list(missing_values.to_dict().keys())\n",
    "missing_values_data = pd.DataFrame(missing_values)\n",
    "missing_values_data.reset_index(level=0, inplace=True)\n",
    "missing_values_data.columns = ['Feature','Number of Missing Values']\n",
    "missing_values_data['Percentage of Missing Values'] = (100.0*missing_values_data['Number of Missing Values'])/len(df_pricing_one)\n",
    "missing_values_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4ec46b",
   "metadata": {},
   "source": [
    "# Removing columns with most missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "721b7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pricing_one.drop([\"PoolQC\"],axis = 1,inplace =True)\n",
    "df_pricing_one.drop([\"MiscFeature\"],axis = 1,inplace =True)\n",
    "df_pricing_one.drop([\"Alley\"],axis = 1,inplace =True)\n",
    "df_pricing_one.drop([\"Fence\"],axis = 1,inplace =True)\n",
    "df_pricing_one.drop([\"FireplaceQu\"],axis = 1,inplace =True)\n",
    "df_pricing_one.drop([\"Id\"],axis = 1,inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae37fa05",
   "metadata": {},
   "source": [
    "# Filling low propability missing values with suitable value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d76e3aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pricing_one['BsmtFinSF1'].fillna(0, inplace=True)\n",
    "df_pricing_one['BsmtFinSF2'].fillna(0, inplace=True)\n",
    "df_pricing_one['TotalBsmtSF'].fillna(0, inplace=True)\n",
    "df_pricing_one['BsmtUnfSF'].fillna(0, inplace=True)\n",
    "df_pricing_one['Electrical'].fillna('FuseA',inplace = True)\n",
    "df_pricing_one['KitchenQual'].fillna('TA',inplace=True)\n",
    "df_pricing_one['LotFrontage'].fillna(df_pricing_one.groupby('1stFlrSF')['LotFrontage'].transform('mean'),inplace=True)\n",
    "df_pricing_one['LotFrontage'].interpolate(method='linear',inplace=True)\n",
    "df_pricing_one['MasVnrArea'].fillna(df_pricing_one.groupby('MasVnrType')['MasVnrArea'].transform('mean'),inplace=True)\n",
    "df_pricing_one['MasVnrArea'].interpolate(method='linear',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da86a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in df_pricing_one.to_dict().keys():\n",
    "    data_type = df_pricing_one[col].dtype\n",
    "    if data_type == 'object':\n",
    "        df_pricing_one[col].fillna('NA',inplace=True)\n",
    "        label = le.fit_transform(df_pricing_one[col])\n",
    "        df_pricing_one.drop(col, axis=1, inplace=True)\n",
    "        df_pricing_one[col] = label\n",
    "        \n",
    "    else:\n",
    "        #data_with_imputed_values = pd.DataFrame(imputer.fit_transform(df_pricing.select_dtypes(exclude=['object'])))\n",
    "        df_pricing_one[col].fillna(df_pricing_one[col].mean(),inplace=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a11725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  Electrical  \\\n",
       "0          2003       196.0       706.0         0.0  ...           4   \n",
       "1          1976         0.0       978.0         0.0  ...           4   \n",
       "2          2002       162.0       486.0         0.0  ...           4   \n",
       "3          1970         0.0       216.0         0.0  ...           4   \n",
       "4          2000       350.0       655.0         0.0  ...           4   \n",
       "\n",
       "   KitchenQual  Functional  GarageType  GarageFinish  GarageQual  GarageCond  \\\n",
       "0            2           7           1             2           5           5   \n",
       "1            3           7           1             2           5           5   \n",
       "2            2           7           1             2           5           5   \n",
       "3            2           7           5             3           5           5   \n",
       "4            2           7           1             2           5           5   \n",
       "\n",
       "   PavedDrive  SaleType  SaleCondition  \n",
       "0           2         9              4  \n",
       "1           2         9              4  \n",
       "2           2         9              4  \n",
       "3           2         9              0  \n",
       "4           2         9              4  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pricing_one.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6af303da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "column_data_type = []\n",
    "for col in df_pricing_one.columns:\n",
    "    data_type = df_pricing_one[col].dtype\n",
    "    if df_pricing_one[col].dtype in ['int64','float64']:\n",
    "        column_data_type.append('numeric')\n",
    "    else:\n",
    "        column_data_type.append('categorical')\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.countplot(x=column_data_type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27891e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 74)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_pricing_one[:1460].copy()\n",
    "test = df_pricing_one[1460:].copy()\n",
    "#train['SalePrice'] = output\n",
    "#train.drop([\"SalePrice\"],axis = 1,inplace =True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866207d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa28fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(train.shape[1])))\n",
    "model.add(tf.keras.layers.Dense(384, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(352, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(448, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(160, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(160, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92a58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26b75437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 2s 34ms/step - loss: 38716801024.0000 - val_loss: 34816884736.0000\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 36500242432.0000 - val_loss: 31184599040.0000\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 29552351232.0000 - val_loss: 20045559808.0000\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 16571078656.0000 - val_loss: 7504588800.0000\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 14719895552.0000 - val_loss: 6158544384.0000\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 11407325184.0000 - val_loss: 6612220416.0000\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 10095045632.0000 - val_loss: 4965235712.0000\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 8603966464.0000 - val_loss: 4318657024.0000\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 7262199808.0000 - val_loss: 3830035200.0000\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 6317879808.0000 - val_loss: 3566421248.0000\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 5633886208.0000 - val_loss: 3358560256.0000\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 5071694848.0000 - val_loss: 3215726080.0000\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 4687424512.0000 - val_loss: 3111670528.0000\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 4400980992.0000 - val_loss: 3016328704.0000\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 4160730112.0000 - val_loss: 2929596160.0000\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 3956251392.0000 - val_loss: 2818850560.0000\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3781244928.0000 - val_loss: 2740753152.0000\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3637081344.0000 - val_loss: 2643625472.0000\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3493032192.0000 - val_loss: 2563457792.0000\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 3354999808.0000 - val_loss: 2471224576.0000\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 3218420736.0000 - val_loss: 2335776512.0000\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 3079713536.0000 - val_loss: 2227381504.0000\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2939773696.0000 - val_loss: 2150615808.0000\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2811968256.0000 - val_loss: 1958560256.0000\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2653283840.0000 - val_loss: 1874904448.0000\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2522092032.0000 - val_loss: 1791006592.0000\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2417909504.0000 - val_loss: 1651616896.0000\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2295680000.0000 - val_loss: 1541544832.0000\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2206266880.0000 - val_loss: 1473364864.0000\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2220700928.0000 - val_loss: 1457885952.0000\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2095474176.0000 - val_loss: 1407990528.0000\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1987522304.0000 - val_loss: 1333264640.0000\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1955629696.0000 - val_loss: 1318454656.0000\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1912654464.0000 - val_loss: 1322924672.0000\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1889838976.0000 - val_loss: 1257073664.0000\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1882318464.0000 - val_loss: 1250572544.0000\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1871656448.0000 - val_loss: 1328886016.0000\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1863307392.0000 - val_loss: 1413185024.0000\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1848052352.0000 - val_loss: 1274699904.0000\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1871521024.0000 - val_loss: 1283468800.0000\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1833948800.0000 - val_loss: 1238643584.0000\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1828779392.0000 - val_loss: 1350762368.0000\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1788745984.0000 - val_loss: 1238669952.0000\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1792591744.0000 - val_loss: 1272585728.0000\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1791438976.0000 - val_loss: 1232007040.0000\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1794788864.0000 - val_loss: 1274178944.0000\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1797920384.0000 - val_loss: 1252010880.0000\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1779937408.0000 - val_loss: 1228990208.0000\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1778235008.0000 - val_loss: 1246689664.0000\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1750265216.0000 - val_loss: 1267342592.0000\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1756551552.0000 - val_loss: 1320066688.0000\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1753158016.0000 - val_loss: 1240013824.0000\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1736712960.0000 - val_loss: 1234534528.0000\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1765339520.0000 - val_loss: 1272481152.0000\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1766158848.0000 - val_loss: 1284003328.0000\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1725963904.0000 - val_loss: 1254972928.0000\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1718385280.0000 - val_loss: 1217675648.0000\n",
      "Epoch 58/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1707367808.0000 - val_loss: 1230416768.0000\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1700965632.0000 - val_loss: 1226140928.0000\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1710284544.0000 - val_loss: 1220247040.0000\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1692762752.0000 - val_loss: 1218677888.0000\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1695080960.0000 - val_loss: 1267120256.0000\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1679221248.0000 - val_loss: 1200543488.0000\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1695751040.0000 - val_loss: 1203856512.0000\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1684646528.0000 - val_loss: 1226145152.0000\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1655939456.0000 - val_loss: 1318013184.0000\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1701636736.0000 - val_loss: 1329443328.0000\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1679699072.0000 - val_loss: 1232539392.0000\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1644001024.0000 - val_loss: 1217600256.0000\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1638789888.0000 - val_loss: 1187348480.0000\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1643160832.0000 - val_loss: 1195682944.0000\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1643115136.0000 - val_loss: 1181323136.0000\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1649711872.0000 - val_loss: 1203152128.0000\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1632151296.0000 - val_loss: 1263600896.0000\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1631271680.0000 - val_loss: 1499452672.0000\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1699607296.0000 - val_loss: 1239338368.0000\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1660837120.0000 - val_loss: 1249371136.0000\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1641093760.0000 - val_loss: 1296361728.0000\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1625817984.0000 - val_loss: 1174305152.0000\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1600654848.0000 - val_loss: 1197284992.0000\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1583526016.0000 - val_loss: 1243096192.0000\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1580327808.0000 - val_loss: 1222472960.0000\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1587176832.0000 - val_loss: 1176597888.0000\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1606199936.0000 - val_loss: 1323943296.0000\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1567949056.0000 - val_loss: 1192631808.0000\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1558782592.0000 - val_loss: 1223445248.0000\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1536810240.0000 - val_loss: 1166641152.0000\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1538492928.0000 - val_loss: 1225985152.0000\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1543966208.0000 - val_loss: 1339768320.0000\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1543197696.0000 - val_loss: 1217133184.0000\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1530010880.0000 - val_loss: 1187664128.0000\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1528059264.0000 - val_loss: 1160912128.0000\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1529510528.0000 - val_loss: 1240426752.0000\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1512911872.0000 - val_loss: 1211173120.0000\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1514968320.0000 - val_loss: 1179722752.0000\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1523423360.0000 - val_loss: 1184480128.0000\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1493440128.0000 - val_loss: 1154712448.0000\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1496512512.0000 - val_loss: 1152470272.0000\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1506392448.0000 - val_loss: 1184310656.0000\n",
      "Epoch 100/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1481192832.0000 - val_loss: 1167108224.0000\n",
      "Epoch 101/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1465251328.0000 - val_loss: 1158296192.0000\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1459997184.0000 - val_loss: 1156334848.0000\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1450086400.0000 - val_loss: 1216930560.0000\n",
      "Epoch 104/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1454608768.0000 - val_loss: 1200461568.0000\n",
      "Epoch 105/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1459124608.0000 - val_loss: 1189250816.0000\n",
      "Epoch 106/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1462273792.0000 - val_loss: 1155781120.0000\n",
      "Epoch 107/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1439597184.0000 - val_loss: 1166914432.0000\n",
      "Epoch 108/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1424890112.0000 - val_loss: 1306202112.0000\n",
      "Epoch 109/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1441692288.0000 - val_loss: 1182565632.0000\n",
      "Epoch 110/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1414530176.0000 - val_loss: 1182357120.0000\n",
      "Epoch 111/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1415665920.0000 - val_loss: 1165951616.0000\n",
      "Epoch 112/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1403639936.0000 - val_loss: 1261003392.0000\n",
      "Epoch 113/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1420554880.0000 - val_loss: 1160690560.0000\n",
      "Epoch 114/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1399148160.0000 - val_loss: 1223613056.0000\n",
      "Epoch 115/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1396514432.0000 - val_loss: 1231704576.0000\n",
      "Epoch 116/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1403199360.0000 - val_loss: 1162549248.0000\n",
      "Epoch 117/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1408891392.0000 - val_loss: 1156046208.0000\n",
      "Epoch 118/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1389829760.0000 - val_loss: 1168689280.0000\n",
      "Epoch 119/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1378733184.0000 - val_loss: 1168480640.0000\n",
      "Epoch 120/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1417100672.0000 - val_loss: 1164604544.0000\n",
      "Epoch 121/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1380074496.0000 - val_loss: 1175049472.0000\n",
      "Epoch 122/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1427456640.0000 - val_loss: 1211070080.0000\n",
      "Epoch 123/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1351786112.0000 - val_loss: 1171935104.0000\n",
      "Epoch 124/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1356715136.0000 - val_loss: 1173886336.0000\n",
      "Epoch 125/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1364528000.0000 - val_loss: 1219995648.0000\n",
      "Epoch 126/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1348228096.0000 - val_loss: 1232365184.0000\n",
      "Epoch 127/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1403232896.0000 - val_loss: 1191696384.0000\n",
      "Epoch 128/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1342827264.0000 - val_loss: 1191685120.0000\n",
      "Epoch 129/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1332224512.0000 - val_loss: 1258217856.0000\n",
      "Epoch 130/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1320010752.0000 - val_loss: 1231508224.0000\n",
      "Epoch 131/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1348806528.0000 - val_loss: 1183989760.0000\n",
      "Epoch 132/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1326883968.0000 - val_loss: 1184320896.0000\n",
      "Epoch 133/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1340810752.0000 - val_loss: 1268364672.0000\n",
      "Epoch 134/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1330677760.0000 - val_loss: 1300236416.0000\n",
      "Epoch 135/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1332421888.0000 - val_loss: 1350351232.0000\n",
      "Epoch 136/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1334559488.0000 - val_loss: 1422534272.0000\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 13ms/step - loss: 1380677504.0000 - val_loss: 1237429376.0000\n",
      "Epoch 138/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1377213440.0000 - val_loss: 1208649088.0000\n",
      "Epoch 139/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1348186240.0000 - val_loss: 1183398400.0000\n",
      "Epoch 140/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1307456512.0000 - val_loss: 1176902656.0000\n",
      "Epoch 141/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1312154112.0000 - val_loss: 1255782528.0000\n",
      "Epoch 142/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1330668160.0000 - val_loss: 1335218304.0000\n",
      "Epoch 143/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1291834880.0000 - val_loss: 1188468224.0000\n",
      "Epoch 144/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1306145152.0000 - val_loss: 1195135616.0000\n",
      "Epoch 145/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1300433792.0000 - val_loss: 1189238272.0000\n",
      "Epoch 146/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1295457664.0000 - val_loss: 1193867520.0000\n",
      "Epoch 147/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1273081728.0000 - val_loss: 1229711488.0000\n",
      "Epoch 148/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1269584768.0000 - val_loss: 1225536128.0000\n",
      "Epoch 149/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1275991808.0000 - val_loss: 1263442176.0000\n",
      "Epoch 150/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1269304448.0000 - val_loss: 1226148992.0000\n",
      "Epoch 151/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1270276992.0000 - val_loss: 1201157632.0000\n",
      "Epoch 152/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1272233088.0000 - val_loss: 1204000000.0000\n",
      "Epoch 153/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1284143744.0000 - val_loss: 1296988288.0000\n",
      "Epoch 154/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1310564352.0000 - val_loss: 1362355840.0000\n",
      "Epoch 155/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1263467776.0000 - val_loss: 1307971968.0000\n",
      "Epoch 156/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1295895936.0000 - val_loss: 1329641216.0000\n",
      "Epoch 157/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1266039424.0000 - val_loss: 1258875904.0000\n",
      "Epoch 158/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1249681152.0000 - val_loss: 1216191232.0000\n",
      "Epoch 159/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1248967296.0000 - val_loss: 1213537024.0000\n",
      "Epoch 160/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1251631872.0000 - val_loss: 1365034752.0000\n",
      "Epoch 161/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1269505408.0000 - val_loss: 1258702336.0000\n",
      "Epoch 162/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1255605760.0000 - val_loss: 1230084352.0000\n",
      "Epoch 163/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1233420160.0000 - val_loss: 1291025024.0000\n",
      "Epoch 164/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1233638272.0000 - val_loss: 1277759872.0000\n",
      "Epoch 165/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1239323520.0000 - val_loss: 1362693248.0000\n",
      "Epoch 166/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1254968576.0000 - val_loss: 1306616448.0000\n",
      "Epoch 167/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1255577728.0000 - val_loss: 1219721856.0000\n",
      "Epoch 168/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1256509312.0000 - val_loss: 1222349696.0000\n",
      "Epoch 169/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1251164672.0000 - val_loss: 1236768000.0000\n",
      "Epoch 170/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1218489856.0000 - val_loss: 1352062336.0000\n",
      "Epoch 171/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1241541120.0000 - val_loss: 1559445248.0000\n",
      "Epoch 172/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1241350656.0000 - val_loss: 1385638656.0000\n",
      "Epoch 173/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1209236992.0000 - val_loss: 1323155584.0000\n",
      "Epoch 174/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1206744832.0000 - val_loss: 1241360640.0000\n",
      "Epoch 175/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1222045952.0000 - val_loss: 1331457152.0000\n",
      "Epoch 176/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1204406400.0000 - val_loss: 1440767488.0000\n",
      "Epoch 177/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1248715392.0000 - val_loss: 1307330944.0000\n",
      "Epoch 178/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1252595200.0000 - val_loss: 1226384384.0000\n",
      "Epoch 179/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1208990848.0000 - val_loss: 1367350656.0000\n",
      "Epoch 180/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1218703488.0000 - val_loss: 1226387968.0000\n",
      "Epoch 181/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1225606528.0000 - val_loss: 1251204992.0000\n",
      "Epoch 182/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1185300608.0000 - val_loss: 1243313536.0000\n",
      "Epoch 183/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1190995968.0000 - val_loss: 1273998464.0000\n",
      "Epoch 184/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1229856256.0000 - val_loss: 1239311488.0000\n",
      "Epoch 185/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1201543040.0000 - val_loss: 1251138944.0000\n",
      "Epoch 186/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1193745408.0000 - val_loss: 1373268224.0000\n",
      "Epoch 187/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1185420928.0000 - val_loss: 1270318336.0000\n",
      "Epoch 188/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1185424896.0000 - val_loss: 1248814464.0000\n",
      "Epoch 189/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1211937280.0000 - val_loss: 1272128512.0000\n",
      "Epoch 190/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1198705408.0000 - val_loss: 1226114560.0000\n",
      "Epoch 191/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1183332096.0000 - val_loss: 1294841344.0000\n",
      "Epoch 192/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1157086464.0000 - val_loss: 1315209088.0000\n",
      "Epoch 193/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1165243392.0000 - val_loss: 1252993792.0000\n",
      "Epoch 194/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1193842176.0000 - val_loss: 1311368064.0000\n",
      "Epoch 195/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1157319808.0000 - val_loss: 1432831616.0000\n",
      "Epoch 196/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1157608448.0000 - val_loss: 1239006720.0000\n",
      "Epoch 197/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1250369664.0000 - val_loss: 1563241088.0000\n",
      "Epoch 198/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1190580992.0000 - val_loss: 1476043264.0000\n",
      "Epoch 199/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1181536128.0000 - val_loss: 1243124608.0000\n",
      "Epoch 200/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1169482880.0000 - val_loss: 1426692864.0000\n",
      "Epoch 201/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1173182336.0000 - val_loss: 1293621888.0000\n",
      "Epoch 202/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1174585728.0000 - val_loss: 1565707392.0000\n",
      "Epoch 203/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1182915072.0000 - val_loss: 1277238016.0000\n",
      "Epoch 204/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1152920832.0000 - val_loss: 1251267328.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 205/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1175561344.0000 - val_loss: 1459948160.0000\n",
      "Epoch 206/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1164626432.0000 - val_loss: 1438340352.0000\n",
      "Epoch 207/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1180849152.0000 - val_loss: 1244317952.0000\n",
      "Epoch 208/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1190812416.0000 - val_loss: 1239540608.0000\n",
      "Epoch 209/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1178137216.0000 - val_loss: 1336481024.0000\n",
      "Epoch 210/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1132440192.0000 - val_loss: 1397590016.0000\n",
      "Epoch 211/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1149289088.0000 - val_loss: 1258741120.0000\n",
      "Epoch 212/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1137480064.0000 - val_loss: 1260822016.0000\n",
      "Epoch 213/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1117700864.0000 - val_loss: 1242288000.0000\n",
      "Epoch 214/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1208648704.0000 - val_loss: 1831128320.0000\n",
      "Epoch 215/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1217862528.0000 - val_loss: 1311228160.0000\n",
      "Epoch 216/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1131664128.0000 - val_loss: 1351209216.0000\n",
      "Epoch 217/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1117259392.0000 - val_loss: 1255600384.0000\n",
      "Epoch 218/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1135408000.0000 - val_loss: 1348277248.0000\n",
      "Epoch 219/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1109264512.0000 - val_loss: 1405380096.0000\n",
      "Epoch 220/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1137806464.0000 - val_loss: 1294780288.0000\n",
      "Epoch 221/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1151524864.0000 - val_loss: 1254708096.0000\n",
      "Epoch 222/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1105572864.0000 - val_loss: 1499230464.0000\n",
      "Epoch 223/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1116151936.0000 - val_loss: 1510245760.0000\n",
      "Epoch 224/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1148993152.0000 - val_loss: 1307752192.0000\n",
      "Epoch 225/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1125753344.0000 - val_loss: 1292119040.0000\n",
      "Epoch 226/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1104119936.0000 - val_loss: 1340584832.0000\n",
      "Epoch 227/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1105246720.0000 - val_loss: 1447006848.0000\n",
      "Epoch 228/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1143281408.0000 - val_loss: 1286604544.0000\n",
      "Epoch 229/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1112637312.0000 - val_loss: 1254192384.0000\n",
      "Epoch 230/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1108442880.0000 - val_loss: 1264609536.0000\n",
      "Epoch 231/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1113292288.0000 - val_loss: 1301803008.0000\n",
      "Epoch 232/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1113337344.0000 - val_loss: 1316656128.0000\n",
      "Epoch 233/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1092131328.0000 - val_loss: 1368161152.0000\n",
      "Epoch 234/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1094185216.0000 - val_loss: 1317799552.0000\n",
      "Epoch 235/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1093418240.0000 - val_loss: 1275450368.0000\n",
      "Epoch 236/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1152182400.0000 - val_loss: 1624890240.0000\n",
      "Epoch 237/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1103874176.0000 - val_loss: 1288695168.0000\n",
      "Epoch 238/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1100446464.0000 - val_loss: 1309855360.0000\n",
      "Epoch 239/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1086983680.0000 - val_loss: 1320171008.0000\n",
      "Epoch 240/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1081673600.0000 - val_loss: 1281622144.0000\n",
      "Epoch 241/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1067317184.0000 - val_loss: 1363257728.0000\n",
      "Epoch 242/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1084301440.0000 - val_loss: 1292960000.0000\n",
      "Epoch 243/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1070138816.0000 - val_loss: 1494390528.0000\n",
      "Epoch 244/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1085420800.0000 - val_loss: 1375964672.0000\n",
      "Epoch 245/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1064543552.0000 - val_loss: 1361400832.0000\n",
      "Epoch 246/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1083255680.0000 - val_loss: 1265781120.0000\n",
      "Epoch 247/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1086662528.0000 - val_loss: 1307829632.0000\n",
      "Epoch 248/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1091466240.0000 - val_loss: 1405791232.0000\n",
      "Epoch 249/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1089962240.0000 - val_loss: 1312864000.0000\n",
      "Epoch 250/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1065569984.0000 - val_loss: 1428319872.0000\n",
      "Epoch 251/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1085020928.0000 - val_loss: 1443887104.0000\n",
      "Epoch 252/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1065060224.0000 - val_loss: 1414324224.0000\n",
      "Epoch 253/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1075780992.0000 - val_loss: 1273302784.0000\n",
      "Epoch 254/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1064043520.0000 - val_loss: 1392736384.0000\n",
      "Epoch 255/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1106474496.0000 - val_loss: 1320969472.0000\n",
      "Epoch 256/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1053171200.0000 - val_loss: 1421372032.0000\n",
      "Epoch 257/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1083819776.0000 - val_loss: 1340446080.0000\n",
      "Epoch 258/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1042027392.0000 - val_loss: 1247539328.0000\n",
      "Epoch 259/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1082750848.0000 - val_loss: 1269252096.0000\n",
      "Epoch 260/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1071601600.0000 - val_loss: 1566663552.0000\n",
      "Epoch 261/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1031893824.0000 - val_loss: 1351994368.0000\n",
      "Epoch 262/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1032065600.0000 - val_loss: 1372955648.0000\n",
      "Epoch 263/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1033393664.0000 - val_loss: 1267424256.0000\n",
      "Epoch 264/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1065834432.0000 - val_loss: 1293016576.0000\n",
      "Epoch 265/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1089951616.0000 - val_loss: 1254079104.0000\n",
      "Epoch 266/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1095778816.0000 - val_loss: 1446529792.0000\n",
      "Epoch 267/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1077497216.0000 - val_loss: 1287396864.0000\n",
      "Epoch 268/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1050638336.0000 - val_loss: 1273548416.0000\n",
      "Epoch 269/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1030904896.0000 - val_loss: 1343708544.0000\n",
      "Epoch 270/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1025885696.0000 - val_loss: 1287510784.0000\n",
      "Epoch 271/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1024205504.0000 - val_loss: 1305016320.0000\n",
      "Epoch 272/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1025856128.0000 - val_loss: 1306462080.0000\n",
      "Epoch 273/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1021302848.0000 - val_loss: 1461687936.0000\n",
      "Epoch 274/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1014979584.0000 - val_loss: 1334560000.0000\n",
      "Epoch 275/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1029194112.0000 - val_loss: 1465164032.0000\n",
      "Epoch 276/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1023082112.0000 - val_loss: 1314591616.0000\n",
      "Epoch 277/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1009297472.0000 - val_loss: 1307219712.0000\n",
      "Epoch 278/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1069161472.0000 - val_loss: 1262377088.0000\n",
      "Epoch 279/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1088828672.0000 - val_loss: 1279579904.0000\n",
      "Epoch 280/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1032170880.0000 - val_loss: 1384846208.0000\n",
      "Epoch 281/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1037264192.0000 - val_loss: 1262003200.0000\n",
      "Epoch 282/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1032221696.0000 - val_loss: 1258688000.0000\n",
      "Epoch 283/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1022062080.0000 - val_loss: 1474173568.0000\n",
      "Epoch 284/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1000280576.0000 - val_loss: 1490621056.0000\n",
      "Epoch 285/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1006805632.0000 - val_loss: 1319548160.0000\n",
      "Epoch 286/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 989867200.0000 - val_loss: 1258728576.0000\n",
      "Epoch 287/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 997065792.0000 - val_loss: 1416376704.0000\n",
      "Epoch 288/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 987481280.0000 - val_loss: 1241069824.0000\n",
      "Epoch 289/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1012543296.0000 - val_loss: 1351352960.0000\n",
      "Epoch 290/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 986706944.0000 - val_loss: 1230626048.0000\n",
      "Epoch 291/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1013406720.0000 - val_loss: 1473926144.0000\n",
      "Epoch 292/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1007713984.0000 - val_loss: 1245544704.0000\n",
      "Epoch 293/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1031911808.0000 - val_loss: 1301799552.0000\n",
      "Epoch 294/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 998117440.0000 - val_loss: 1218247296.0000\n",
      "Epoch 295/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1015773504.0000 - val_loss: 1442989824.0000\n",
      "Epoch 296/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1045058624.0000 - val_loss: 1251131648.0000\n",
      "Epoch 297/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 991458432.0000 - val_loss: 1365401088.0000\n",
      "Epoch 298/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 981056064.0000 - val_loss: 1350549120.0000\n",
      "Epoch 299/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 969231744.0000 - val_loss: 1324050176.0000\n",
      "Epoch 300/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 988382144.0000 - val_loss: 1487647616.0000\n",
      "Epoch 301/1000\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 972392064.0000 - val_loss: 1390495104.0000\n",
      "Epoch 302/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 968737920.0000 - val_loss: 1358099328.0000\n",
      "Epoch 303/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 964303872.0000 - val_loss: 1351423872.0000\n",
      "Epoch 304/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 984376576.0000 - val_loss: 1280814208.0000\n",
      "Epoch 305/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1006050496.0000 - val_loss: 1255136128.0000\n",
      "Epoch 306/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1014397440.0000 - val_loss: 1338327040.0000\n",
      "Epoch 307/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 986076416.0000 - val_loss: 1314711808.0000\n",
      "Epoch 308/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 950638656.0000 - val_loss: 1266933376.0000\n",
      "Epoch 309/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 948559360.0000 - val_loss: 1272276864.0000\n",
      "Epoch 310/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 941095360.0000 - val_loss: 1354901248.0000\n",
      "Epoch 311/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 954661632.0000 - val_loss: 1343160192.0000\n",
      "Epoch 312/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 939744576.0000 - val_loss: 1616238592.0000\n",
      "Epoch 313/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 975831168.0000 - val_loss: 1291524224.0000\n",
      "Epoch 314/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 955225600.0000 - val_loss: 1381730816.0000\n",
      "Epoch 315/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 945264512.0000 - val_loss: 1219063552.0000\n",
      "Epoch 316/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1006266176.0000 - val_loss: 1346381184.0000\n",
      "Epoch 317/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 933462336.0000 - val_loss: 1315121152.0000\n",
      "Epoch 318/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 936601024.0000 - val_loss: 1282087552.0000\n",
      "Epoch 319/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 938075520.0000 - val_loss: 1254113792.0000\n",
      "Epoch 320/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 933779968.0000 - val_loss: 1264326400.0000\n",
      "Epoch 321/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 929288896.0000 - val_loss: 1312030336.0000\n",
      "Epoch 322/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 952496320.0000 - val_loss: 1568030848.0000\n",
      "Epoch 323/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1013382144.0000 - val_loss: 1514123520.0000\n",
      "Epoch 324/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 922198464.0000 - val_loss: 1228274944.0000\n",
      "Epoch 325/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 943528960.0000 - val_loss: 1353486848.0000\n",
      "Epoch 326/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 932974912.0000 - val_loss: 1312553600.0000\n",
      "Epoch 327/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 934445824.0000 - val_loss: 1375766528.0000\n",
      "Epoch 328/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 920062976.0000 - val_loss: 1222805504.0000\n",
      "Epoch 329/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 955354880.0000 - val_loss: 1341142528.0000\n",
      "Epoch 330/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 939387840.0000 - val_loss: 1342126720.0000\n",
      "Epoch 331/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 956852928.0000 - val_loss: 1210652672.0000\n",
      "Epoch 332/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 929891584.0000 - val_loss: 1359698944.0000\n",
      "Epoch 333/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 946630400.0000 - val_loss: 1204736000.0000\n",
      "Epoch 334/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 920175744.0000 - val_loss: 1283927936.0000\n",
      "Epoch 335/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 914973824.0000 - val_loss: 1290423424.0000\n",
      "Epoch 336/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 901910208.0000 - val_loss: 1252731392.0000\n",
      "Epoch 337/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 934508736.0000 - val_loss: 1487179008.0000\n",
      "Epoch 338/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 940728896.0000 - val_loss: 1250621440.0000\n",
      "Epoch 339/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 924304256.0000 - val_loss: 1453399936.0000\n",
      "Epoch 340/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 11ms/step - loss: 922390400.0000 - val_loss: 1235345664.0000\n",
      "Epoch 341/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 902129152.0000 - val_loss: 1370935296.0000\n",
      "Epoch 342/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 896792832.0000 - val_loss: 1431365760.0000\n",
      "Epoch 343/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 904775552.0000 - val_loss: 1225054464.0000\n",
      "Epoch 344/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 898617536.0000 - val_loss: 1425965568.0000\n",
      "Epoch 345/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 891894080.0000 - val_loss: 1202646656.0000\n",
      "Epoch 346/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 900177280.0000 - val_loss: 1250581120.0000\n",
      "Epoch 347/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 879882752.0000 - val_loss: 1302739584.0000\n",
      "Epoch 348/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 870543040.0000 - val_loss: 1486950528.0000\n",
      "Epoch 349/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 879907712.0000 - val_loss: 1289856384.0000\n",
      "Epoch 350/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 874884736.0000 - val_loss: 1197563136.0000\n",
      "Epoch 351/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 891201344.0000 - val_loss: 1488562816.0000\n",
      "Epoch 352/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 885028480.0000 - val_loss: 1235950592.0000\n",
      "Epoch 353/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 869368960.0000 - val_loss: 1258383872.0000\n",
      "Epoch 354/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 874101120.0000 - val_loss: 1245549312.0000\n",
      "Epoch 355/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 856376576.0000 - val_loss: 1322504320.0000\n",
      "Epoch 356/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 884114240.0000 - val_loss: 1189474304.0000\n",
      "Epoch 357/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 872195392.0000 - val_loss: 1316382464.0000\n",
      "Epoch 358/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 884431360.0000 - val_loss: 1275272576.0000\n",
      "Epoch 359/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 883256128.0000 - val_loss: 1209155584.0000\n",
      "Epoch 360/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 876816128.0000 - val_loss: 1450822272.0000\n",
      "Epoch 361/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 947406080.0000 - val_loss: 1171238912.0000\n",
      "Epoch 362/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 876310464.0000 - val_loss: 1316220544.0000\n",
      "Epoch 363/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 871864320.0000 - val_loss: 1212530304.0000\n",
      "Epoch 364/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1006964416.0000 - val_loss: 1472654720.0000\n",
      "Epoch 365/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 909391872.0000 - val_loss: 1214766720.0000\n",
      "Epoch 366/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 843040640.0000 - val_loss: 1168443904.0000\n",
      "Epoch 367/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 869907392.0000 - val_loss: 1385827456.0000\n",
      "Epoch 368/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 892648128.0000 - val_loss: 1339911296.0000\n",
      "Epoch 369/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 910239104.0000 - val_loss: 1226429312.0000\n",
      "Epoch 370/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 867220032.0000 - val_loss: 1227483264.0000\n",
      "Epoch 371/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 841187264.0000 - val_loss: 1441919104.0000\n",
      "Epoch 372/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 871921088.0000 - val_loss: 1170685568.0000\n",
      "Epoch 373/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 851871424.0000 - val_loss: 1345790336.0000\n",
      "Epoch 374/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 831426432.0000 - val_loss: 1207883264.0000\n",
      "Epoch 375/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 876144768.0000 - val_loss: 1807362560.0000\n",
      "Epoch 376/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 965042240.0000 - val_loss: 1213964672.0000\n",
      "Epoch 377/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 854111424.0000 - val_loss: 1154084736.0000\n",
      "Epoch 378/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 877352896.0000 - val_loss: 1221282048.0000\n",
      "Epoch 379/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 838279936.0000 - val_loss: 1295836416.0000\n",
      "Epoch 380/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 852638208.0000 - val_loss: 1197346304.0000\n",
      "Epoch 381/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 849804800.0000 - val_loss: 1319983232.0000\n",
      "Epoch 382/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 836844224.0000 - val_loss: 1264812288.0000\n",
      "Epoch 383/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 819549696.0000 - val_loss: 1368907904.0000\n",
      "Epoch 384/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 814099776.0000 - val_loss: 1167935488.0000\n",
      "Epoch 385/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 810373056.0000 - val_loss: 1467884160.0000\n",
      "Epoch 386/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 824550784.0000 - val_loss: 1175470848.0000\n",
      "Epoch 387/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 798762368.0000 - val_loss: 1214199552.0000\n",
      "Epoch 388/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 804463872.0000 - val_loss: 1320945664.0000\n",
      "Epoch 389/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 854440320.0000 - val_loss: 1136599552.0000\n",
      "Epoch 390/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 825601856.0000 - val_loss: 1229756928.0000\n",
      "Epoch 391/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 831666048.0000 - val_loss: 1192617600.0000\n",
      "Epoch 392/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 808523200.0000 - val_loss: 1135713408.0000\n",
      "Epoch 393/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 828665920.0000 - val_loss: 1246708224.0000\n",
      "Epoch 394/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 800593024.0000 - val_loss: 1158073344.0000\n",
      "Epoch 395/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 808820544.0000 - val_loss: 1146063104.0000\n",
      "Epoch 396/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 800448896.0000 - val_loss: 1168747136.0000\n",
      "Epoch 397/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 794347712.0000 - val_loss: 1141956608.0000\n",
      "Epoch 398/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 831258752.0000 - val_loss: 1150331008.0000\n",
      "Epoch 399/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 800253184.0000 - val_loss: 1200030464.0000\n",
      "Epoch 400/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 783889024.0000 - val_loss: 1259784448.0000\n",
      "Epoch 401/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 806619648.0000 - val_loss: 1208370048.0000\n",
      "Epoch 402/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 831460352.0000 - val_loss: 1125949952.0000\n",
      "Epoch 403/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 849804096.0000 - val_loss: 1318251904.0000\n",
      "Epoch 404/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 822293056.0000 - val_loss: 1248911488.0000\n",
      "Epoch 405/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 776115136.0000 - val_loss: 1118820608.0000\n",
      "Epoch 406/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 784896768.0000 - val_loss: 1269876096.0000\n",
      "Epoch 407/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 817503488.0000 - val_loss: 1128531328.0000\n",
      "Epoch 408/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 808361600.0000 - val_loss: 1307172480.0000\n",
      "Epoch 409/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 775670400.0000 - val_loss: 1111248768.0000\n",
      "Epoch 410/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 773131520.0000 - val_loss: 1159583104.0000\n",
      "Epoch 411/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 768085312.0000 - val_loss: 1243535488.0000\n",
      "Epoch 412/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 768240448.0000 - val_loss: 1121283072.0000\n",
      "Epoch 413/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 778460544.0000 - val_loss: 1151306624.0000\n",
      "Epoch 414/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 757280000.0000 - val_loss: 1193485568.0000\n",
      "Epoch 415/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 754916992.0000 - val_loss: 1139559040.0000\n",
      "Epoch 416/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 748954880.0000 - val_loss: 1273363968.0000\n",
      "Epoch 417/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 786654080.0000 - val_loss: 1099573120.0000\n",
      "Epoch 418/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 791138176.0000 - val_loss: 1157482624.0000\n",
      "Epoch 419/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 782631616.0000 - val_loss: 1233065216.0000\n",
      "Epoch 420/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 733150848.0000 - val_loss: 1166597120.0000\n",
      "Epoch 421/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 750476480.0000 - val_loss: 1248860672.0000\n",
      "Epoch 422/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 755271936.0000 - val_loss: 1093644672.0000\n",
      "Epoch 423/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 748519040.0000 - val_loss: 1308821504.0000\n",
      "Epoch 424/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 754442048.0000 - val_loss: 1324831232.0000\n",
      "Epoch 425/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 761016256.0000 - val_loss: 1184809344.0000\n",
      "Epoch 426/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 723400512.0000 - val_loss: 1113379712.0000\n",
      "Epoch 427/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 733791104.0000 - val_loss: 1214553600.0000\n",
      "Epoch 428/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 730016256.0000 - val_loss: 1168093056.0000\n",
      "Epoch 429/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 729249984.0000 - val_loss: 1095732352.0000\n",
      "Epoch 430/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 728732480.0000 - val_loss: 1535669248.0000\n",
      "Epoch 431/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 747083776.0000 - val_loss: 1078709888.0000\n",
      "Epoch 432/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 751412928.0000 - val_loss: 1170139136.0000\n",
      "Epoch 433/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 715322176.0000 - val_loss: 1189730176.0000\n",
      "Epoch 434/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 738225600.0000 - val_loss: 1085047296.0000\n",
      "Epoch 435/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 793496192.0000 - val_loss: 1099143424.0000\n",
      "Epoch 436/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 722069888.0000 - val_loss: 1054270784.0000\n",
      "Epoch 437/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 729288384.0000 - val_loss: 1104006784.0000\n",
      "Epoch 438/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 740356544.0000 - val_loss: 1205733376.0000\n",
      "Epoch 439/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 729051264.0000 - val_loss: 1150183040.0000\n",
      "Epoch 440/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 715657984.0000 - val_loss: 1118772736.0000\n",
      "Epoch 441/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 708814656.0000 - val_loss: 1179538304.0000\n",
      "Epoch 442/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 734736000.0000 - val_loss: 1189700480.0000\n",
      "Epoch 443/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 711142656.0000 - val_loss: 1090701696.0000\n",
      "Epoch 444/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 702523648.0000 - val_loss: 1081557760.0000\n",
      "Epoch 445/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 700111936.0000 - val_loss: 1045624320.0000\n",
      "Epoch 446/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 700724864.0000 - val_loss: 1119872384.0000\n",
      "Epoch 447/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 697256832.0000 - val_loss: 1186758272.0000\n",
      "Epoch 448/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 741265152.0000 - val_loss: 1281853184.0000\n",
      "Epoch 449/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 759824704.0000 - val_loss: 1120022912.0000\n",
      "Epoch 450/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 683852672.0000 - val_loss: 1175393664.0000\n",
      "Epoch 451/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 696204288.0000 - val_loss: 1210247936.0000\n",
      "Epoch 452/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 720977600.0000 - val_loss: 1202586368.0000\n",
      "Epoch 453/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 690902016.0000 - val_loss: 1035306624.0000\n",
      "Epoch 454/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 724206016.0000 - val_loss: 1034941568.0000\n",
      "Epoch 455/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 696971392.0000 - val_loss: 1029284160.0000\n",
      "Epoch 456/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 680869184.0000 - val_loss: 1505098368.0000\n",
      "Epoch 457/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 742091584.0000 - val_loss: 1101053696.0000\n",
      "Epoch 458/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 711191040.0000 - val_loss: 1001428544.0000\n",
      "Epoch 459/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 703884736.0000 - val_loss: 1013245824.0000\n",
      "Epoch 460/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 670718720.0000 - val_loss: 1018874944.0000\n",
      "Epoch 461/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 671867456.0000 - val_loss: 1039756032.0000\n",
      "Epoch 462/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 659209856.0000 - val_loss: 1231390336.0000\n",
      "Epoch 463/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 663664384.0000 - val_loss: 1146618368.0000\n",
      "Epoch 464/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 654098432.0000 - val_loss: 1135046656.0000\n",
      "Epoch 465/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 670211520.0000 - val_loss: 1044626752.0000\n",
      "Epoch 466/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 660437312.0000 - val_loss: 1008113792.0000\n",
      "Epoch 467/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 823224448.0000 - val_loss: 1069277056.0000\n",
      "Epoch 468/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 673391936.0000 - val_loss: 1051637760.0000\n",
      "Epoch 469/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 659130944.0000 - val_loss: 1220630016.0000\n",
      "Epoch 470/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 754220032.0000 - val_loss: 1414917248.0000\n",
      "Epoch 471/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 680968640.0000 - val_loss: 1018839616.0000\n",
      "Epoch 472/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 650132736.0000 - val_loss: 1188347776.0000\n",
      "Epoch 473/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 696863296.0000 - val_loss: 1090147712.0000\n",
      "Epoch 474/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 675331392.0000 - val_loss: 1204680960.0000\n",
      "Epoch 475/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 641586240.0000 - val_loss: 1008690176.0000\n",
      "Epoch 476/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 12ms/step - loss: 659165696.0000 - val_loss: 1015450944.0000\n",
      "Epoch 477/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 646430272.0000 - val_loss: 1009264704.0000\n",
      "Epoch 478/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 635947328.0000 - val_loss: 1179185152.0000\n",
      "Epoch 479/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 665543744.0000 - val_loss: 1167990656.0000\n",
      "Epoch 480/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 666842176.0000 - val_loss: 1090789120.0000\n",
      "Epoch 481/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 640464704.0000 - val_loss: 1049734912.0000\n",
      "Epoch 482/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 617745472.0000 - val_loss: 965051968.0000\n",
      "Epoch 483/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 635295040.0000 - val_loss: 1175390848.0000\n",
      "Epoch 484/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 668818944.0000 - val_loss: 1059790720.0000\n",
      "Epoch 485/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 652488512.0000 - val_loss: 1079058560.0000\n",
      "Epoch 486/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 642434112.0000 - val_loss: 1008906880.0000\n",
      "Epoch 487/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 666306752.0000 - val_loss: 1084896640.0000\n",
      "Epoch 488/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 643521728.0000 - val_loss: 955604544.0000\n",
      "Epoch 489/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 665295040.0000 - val_loss: 1072077248.0000\n",
      "Epoch 490/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 659549504.0000 - val_loss: 1026959360.0000\n",
      "Epoch 491/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 625875392.0000 - val_loss: 949709696.0000\n",
      "Epoch 492/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 644299584.0000 - val_loss: 1137096448.0000\n",
      "Epoch 493/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 643023808.0000 - val_loss: 1264966016.0000\n",
      "Epoch 494/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 672534976.0000 - val_loss: 1030325248.0000\n",
      "Epoch 495/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 632887680.0000 - val_loss: 971444736.0000\n",
      "Epoch 496/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 603472960.0000 - val_loss: 965539328.0000\n",
      "Epoch 497/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 639990144.0000 - val_loss: 954168256.0000\n",
      "Epoch 498/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 609280512.0000 - val_loss: 979566464.0000\n",
      "Epoch 499/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 594735424.0000 - val_loss: 1027475776.0000\n",
      "Epoch 500/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 601180992.0000 - val_loss: 946628928.0000\n",
      "Epoch 501/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 606184896.0000 - val_loss: 1293979264.0000\n",
      "Epoch 502/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 629912384.0000 - val_loss: 1165427712.0000\n",
      "Epoch 503/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 627531136.0000 - val_loss: 1094723840.0000\n",
      "Epoch 504/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 598392256.0000 - val_loss: 1118506112.0000\n",
      "Epoch 505/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 606566848.0000 - val_loss: 975596480.0000\n",
      "Epoch 506/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 587605568.0000 - val_loss: 924295168.0000\n",
      "Epoch 507/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 596887552.0000 - val_loss: 1019542336.0000\n",
      "Epoch 508/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 593993920.0000 - val_loss: 969560256.0000\n",
      "Epoch 509/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 643823680.0000 - val_loss: 940851648.0000\n",
      "Epoch 510/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 580544832.0000 - val_loss: 1044470016.0000\n",
      "Epoch 511/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 580083072.0000 - val_loss: 1091086592.0000\n",
      "Epoch 512/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 582423104.0000 - val_loss: 947345856.0000\n",
      "Epoch 513/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 599040512.0000 - val_loss: 910168576.0000\n",
      "Epoch 514/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 579453888.0000 - val_loss: 1035154112.0000\n",
      "Epoch 515/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 597130944.0000 - val_loss: 932527488.0000\n",
      "Epoch 516/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 630462592.0000 - val_loss: 932525248.0000\n",
      "Epoch 517/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 599065472.0000 - val_loss: 1083875584.0000\n",
      "Epoch 518/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 574134592.0000 - val_loss: 905114304.0000\n",
      "Epoch 519/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 598766464.0000 - val_loss: 940738432.0000\n",
      "Epoch 520/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 612626752.0000 - val_loss: 1073399808.0000\n",
      "Epoch 521/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 565415616.0000 - val_loss: 902502336.0000\n",
      "Epoch 522/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 578573632.0000 - val_loss: 906849600.0000\n",
      "Epoch 523/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 577842496.0000 - val_loss: 912136896.0000\n",
      "Epoch 524/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 612576640.0000 - val_loss: 1065116864.0000\n",
      "Epoch 525/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 572547392.0000 - val_loss: 930371392.0000\n",
      "Epoch 526/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 644590464.0000 - val_loss: 957291072.0000\n",
      "Epoch 527/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 570597184.0000 - val_loss: 917142528.0000\n",
      "Epoch 528/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 586427648.0000 - val_loss: 890155008.0000\n",
      "Epoch 529/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 565418496.0000 - val_loss: 1141267200.0000\n",
      "Epoch 530/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 589936768.0000 - val_loss: 1193920768.0000\n",
      "Epoch 531/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 589329408.0000 - val_loss: 1125558144.0000\n",
      "Epoch 532/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 564791616.0000 - val_loss: 961473280.0000\n",
      "Epoch 533/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 538877760.0000 - val_loss: 960607296.0000\n",
      "Epoch 534/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 558998080.0000 - val_loss: 907202496.0000\n",
      "Epoch 535/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 565783168.0000 - val_loss: 956568704.0000\n",
      "Epoch 536/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 565724288.0000 - val_loss: 933689984.0000\n",
      "Epoch 537/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 593284992.0000 - val_loss: 940639552.0000\n",
      "Epoch 538/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 542261952.0000 - val_loss: 954489408.0000\n",
      "Epoch 539/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 576723072.0000 - val_loss: 893583808.0000\n",
      "Epoch 540/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 551577088.0000 - val_loss: 934852992.0000\n",
      "Epoch 541/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 545143744.0000 - val_loss: 944152448.0000\n",
      "Epoch 542/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 566727488.0000 - val_loss: 1003924224.0000\n",
      "Epoch 543/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 528387904.0000 - val_loss: 880471744.0000\n",
      "Epoch 544/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 539440256.0000 - val_loss: 998134848.0000\n",
      "Epoch 545/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 596223360.0000 - val_loss: 1147947648.0000\n",
      "Epoch 546/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 524241472.0000 - val_loss: 885834304.0000\n",
      "Epoch 547/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 564152064.0000 - val_loss: 887835520.0000\n",
      "Epoch 548/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 543127232.0000 - val_loss: 936069056.0000\n",
      "Epoch 549/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 557431872.0000 - val_loss: 1013529408.0000\n",
      "Epoch 550/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 521460288.0000 - val_loss: 921904768.0000\n",
      "Epoch 551/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 517000672.0000 - val_loss: 881416576.0000\n",
      "Epoch 552/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 566715264.0000 - val_loss: 1103885824.0000\n",
      "Epoch 553/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 543018624.0000 - val_loss: 868588416.0000\n",
      "Epoch 554/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 524030752.0000 - val_loss: 949961024.0000\n",
      "Epoch 555/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 576142656.0000 - val_loss: 920712448.0000\n",
      "Epoch 556/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 559159296.0000 - val_loss: 903099648.0000\n",
      "Epoch 557/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 526625792.0000 - val_loss: 969875776.0000\n",
      "Epoch 558/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 527328544.0000 - val_loss: 871856512.0000\n",
      "Epoch 559/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 536874176.0000 - val_loss: 1041628480.0000\n",
      "Epoch 560/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 503666048.0000 - val_loss: 954929344.0000\n",
      "Epoch 561/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 526629600.0000 - val_loss: 883028224.0000\n",
      "Epoch 562/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 521401984.0000 - val_loss: 886239360.0000\n",
      "Epoch 563/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 526636608.0000 - val_loss: 1045814400.0000\n",
      "Epoch 564/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 526225888.0000 - val_loss: 877340992.0000\n",
      "Epoch 565/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 497003712.0000 - val_loss: 985852800.0000\n",
      "Epoch 566/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 538260160.0000 - val_loss: 883815936.0000\n",
      "Epoch 567/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 542053312.0000 - val_loss: 1313347712.0000\n",
      "Epoch 568/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 585013568.0000 - val_loss: 1083136896.0000\n",
      "Epoch 569/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 565879296.0000 - val_loss: 885514176.0000\n",
      "Epoch 570/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 521715648.0000 - val_loss: 869529792.0000\n",
      "Epoch 571/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 506060768.0000 - val_loss: 1008442368.0000\n",
      "Epoch 572/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 520791712.0000 - val_loss: 870911744.0000\n",
      "Epoch 573/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 496887520.0000 - val_loss: 882608128.0000\n",
      "Epoch 574/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 510534560.0000 - val_loss: 858106176.0000\n",
      "Epoch 575/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 505403616.0000 - val_loss: 870270080.0000\n",
      "Epoch 576/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 495430912.0000 - val_loss: 864121856.0000\n",
      "Epoch 577/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 495187136.0000 - val_loss: 968472384.0000\n",
      "Epoch 578/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 527198880.0000 - val_loss: 1157484928.0000\n",
      "Epoch 579/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 530623136.0000 - val_loss: 926019456.0000\n",
      "Epoch 580/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 522334080.0000 - val_loss: 1016923776.0000\n",
      "Epoch 581/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 487160352.0000 - val_loss: 860011072.0000\n",
      "Epoch 582/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 536242496.0000 - val_loss: 882584448.0000\n",
      "Epoch 583/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 493740256.0000 - val_loss: 849432384.0000\n",
      "Epoch 584/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 519554656.0000 - val_loss: 973348736.0000\n",
      "Epoch 585/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 502750592.0000 - val_loss: 923112384.0000\n",
      "Epoch 586/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 479925824.0000 - val_loss: 841691136.0000\n",
      "Epoch 587/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 499490368.0000 - val_loss: 903216384.0000\n",
      "Epoch 588/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 490680960.0000 - val_loss: 1035557696.0000\n",
      "Epoch 589/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 510703552.0000 - val_loss: 847281216.0000\n",
      "Epoch 590/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 493119488.0000 - val_loss: 1006527040.0000\n",
      "Epoch 591/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 507412032.0000 - val_loss: 913444864.0000\n",
      "Epoch 592/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 521893440.0000 - val_loss: 921727488.0000\n",
      "Epoch 593/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 491120448.0000 - val_loss: 891494144.0000\n",
      "Epoch 594/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 519150048.0000 - val_loss: 905477376.0000\n",
      "Epoch 595/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 494326112.0000 - val_loss: 869831040.0000\n",
      "Epoch 596/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 509944608.0000 - val_loss: 1034932288.0000\n",
      "Epoch 597/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 563454208.0000 - val_loss: 846033728.0000\n",
      "Epoch 598/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 483119680.0000 - val_loss: 886807680.0000\n",
      "Epoch 599/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 519375840.0000 - val_loss: 865188864.0000\n",
      "Epoch 600/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 481143552.0000 - val_loss: 873837376.0000\n",
      "Epoch 601/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 475293504.0000 - val_loss: 834005504.0000\n",
      "Epoch 602/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 482016736.0000 - val_loss: 918949248.0000\n",
      "Epoch 603/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 510166400.0000 - val_loss: 1063133312.0000\n",
      "Epoch 604/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 530312672.0000 - val_loss: 828939968.0000\n",
      "Epoch 605/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 507618912.0000 - val_loss: 864175616.0000\n",
      "Epoch 606/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 472391232.0000 - val_loss: 884792640.0000\n",
      "Epoch 607/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 497306912.0000 - val_loss: 902216256.0000\n",
      "Epoch 608/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 465603040.0000 - val_loss: 916227904.0000\n",
      "Epoch 609/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 498633856.0000 - val_loss: 1105105152.0000\n",
      "Epoch 610/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 512625120.0000 - val_loss: 841069248.0000\n",
      "Epoch 611/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 481097376.0000 - val_loss: 876500608.0000\n",
      "Epoch 612/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 461532000.0000 - val_loss: 829647808.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 613/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 481298144.0000 - val_loss: 909230784.0000\n",
      "Epoch 614/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 486582112.0000 - val_loss: 931758592.0000\n",
      "Epoch 615/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 475396640.0000 - val_loss: 826974528.0000\n",
      "Epoch 616/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 457857024.0000 - val_loss: 840466560.0000\n",
      "Epoch 617/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 474276800.0000 - val_loss: 859358336.0000\n",
      "Epoch 618/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 455972608.0000 - val_loss: 1174656640.0000\n",
      "Epoch 619/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 486158976.0000 - val_loss: 830957632.0000\n",
      "Epoch 620/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 468912064.0000 - val_loss: 887114944.0000\n",
      "Epoch 621/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 457579200.0000 - val_loss: 857195712.0000\n",
      "Epoch 622/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 454442432.0000 - val_loss: 854534144.0000\n",
      "Epoch 623/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 463459328.0000 - val_loss: 833330176.0000\n",
      "Epoch 624/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 455391552.0000 - val_loss: 895373248.0000\n",
      "Epoch 625/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 446370592.0000 - val_loss: 846893760.0000\n",
      "Epoch 626/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 467250720.0000 - val_loss: 1111483008.0000\n",
      "Epoch 627/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 535065536.0000 - val_loss: 836994624.0000\n",
      "Epoch 628/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 459794304.0000 - val_loss: 881468672.0000\n",
      "Epoch 629/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 484320672.0000 - val_loss: 928473472.0000\n",
      "Epoch 630/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 466062848.0000 - val_loss: 988509760.0000\n",
      "Epoch 631/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 469860512.0000 - val_loss: 958333504.0000\n",
      "Epoch 632/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 455037440.0000 - val_loss: 931804608.0000\n",
      "Epoch 633/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 492625088.0000 - val_loss: 831437184.0000\n",
      "Epoch 634/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 485263648.0000 - val_loss: 958129792.0000\n",
      "Epoch 635/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 462278112.0000 - val_loss: 852169920.0000\n",
      "Epoch 636/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 445129632.0000 - val_loss: 853698304.0000\n",
      "Epoch 637/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 455520448.0000 - val_loss: 843814208.0000\n",
      "Epoch 638/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 456668448.0000 - val_loss: 892479424.0000\n",
      "Epoch 639/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 446765152.0000 - val_loss: 904199808.0000\n",
      "Epoch 640/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 448428832.0000 - val_loss: 857403392.0000\n",
      "Epoch 641/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 440410144.0000 - val_loss: 851197312.0000\n",
      "Epoch 642/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 466918848.0000 - val_loss: 1281815040.0000\n",
      "Epoch 643/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 458581376.0000 - val_loss: 850346240.0000\n",
      "Epoch 644/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 465128288.0000 - val_loss: 941610240.0000\n",
      "Epoch 645/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 447703584.0000 - val_loss: 836176768.0000\n",
      "Epoch 646/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 448442560.0000 - val_loss: 926512256.0000\n",
      "Epoch 647/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 454181152.0000 - val_loss: 957316992.0000\n",
      "Epoch 648/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 447920768.0000 - val_loss: 841695360.0000\n",
      "Epoch 649/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 434788576.0000 - val_loss: 835688640.0000\n",
      "Epoch 650/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 524220480.0000 - val_loss: 824071424.0000\n",
      "Epoch 651/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 481072288.0000 - val_loss: 941274624.0000\n",
      "Epoch 652/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 490267424.0000 - val_loss: 998770240.0000\n",
      "Epoch 653/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 487101920.0000 - val_loss: 811442176.0000\n",
      "Epoch 654/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 447395424.0000 - val_loss: 813631808.0000\n",
      "Epoch 655/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 445889984.0000 - val_loss: 899389760.0000\n",
      "Epoch 656/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 453010976.0000 - val_loss: 1012440384.0000\n",
      "Epoch 657/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 460082976.0000 - val_loss: 828876352.0000\n",
      "Epoch 658/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 500249664.0000 - val_loss: 1227474432.0000\n",
      "Epoch 659/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 473223136.0000 - val_loss: 816549312.0000\n",
      "Epoch 660/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 446434560.0000 - val_loss: 1260303232.0000\n",
      "Epoch 661/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 462869792.0000 - val_loss: 833573120.0000\n",
      "Epoch 662/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 431181728.0000 - val_loss: 816596352.0000\n",
      "Epoch 663/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 430290784.0000 - val_loss: 830125312.0000\n",
      "Epoch 664/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 459301984.0000 - val_loss: 825563072.0000\n",
      "Epoch 665/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 454819200.0000 - val_loss: 961193280.0000\n",
      "Epoch 666/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 443669088.0000 - val_loss: 841984000.0000\n",
      "Epoch 667/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 445175680.0000 - val_loss: 895277888.0000\n",
      "Epoch 668/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 425716320.0000 - val_loss: 924931136.0000\n",
      "Epoch 669/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 426570080.0000 - val_loss: 832119104.0000\n",
      "Epoch 670/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 424751968.0000 - val_loss: 952324288.0000\n",
      "Epoch 671/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 431044832.0000 - val_loss: 810826624.0000\n",
      "Epoch 672/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 422915264.0000 - val_loss: 827758592.0000\n",
      "Epoch 673/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 418088448.0000 - val_loss: 848513984.0000\n",
      "Epoch 674/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 424744800.0000 - val_loss: 928931136.0000\n",
      "Epoch 675/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 426152672.0000 - val_loss: 872878528.0000\n",
      "Epoch 676/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 430111072.0000 - val_loss: 823628672.0000\n",
      "Epoch 677/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 418767808.0000 - val_loss: 824221568.0000\n",
      "Epoch 678/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 436332608.0000 - val_loss: 815393536.0000\n",
      "Epoch 679/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 450903200.0000 - val_loss: 875668608.0000\n",
      "Epoch 680/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 428698816.0000 - val_loss: 920200128.0000\n",
      "Epoch 681/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 421592576.0000 - val_loss: 850662848.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 682/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 483425152.0000 - val_loss: 1429978624.0000\n",
      "Epoch 683/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 571555328.0000 - val_loss: 854808000.0000\n",
      "Epoch 684/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 469300608.0000 - val_loss: 1010897856.0000\n",
      "Epoch 685/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 432036256.0000 - val_loss: 810040192.0000\n",
      "Epoch 686/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 438292992.0000 - val_loss: 807955648.0000\n",
      "Epoch 687/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 429655904.0000 - val_loss: 902180352.0000\n",
      "Epoch 688/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 441960480.0000 - val_loss: 901559424.0000\n",
      "Epoch 689/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 508935712.0000 - val_loss: 957204032.0000\n",
      "Epoch 690/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 464703072.0000 - val_loss: 938209024.0000\n",
      "Epoch 691/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 412528288.0000 - val_loss: 918075584.0000\n",
      "Epoch 692/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 448200000.0000 - val_loss: 839157760.0000\n",
      "Epoch 693/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 428642560.0000 - val_loss: 1062899072.0000\n",
      "Epoch 694/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 576009792.0000 - val_loss: 813079808.0000\n",
      "Epoch 695/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 459446176.0000 - val_loss: 920156608.0000\n",
      "Epoch 696/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 423543008.0000 - val_loss: 828214272.0000\n",
      "Epoch 697/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408669792.0000 - val_loss: 821731456.0000\n",
      "Epoch 698/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 404895680.0000 - val_loss: 844171968.0000\n",
      "Epoch 699/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 409780672.0000 - val_loss: 837181632.0000\n",
      "Epoch 700/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 439558528.0000 - val_loss: 993397824.0000\n",
      "Epoch 701/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 411861280.0000 - val_loss: 921426368.0000\n",
      "Epoch 702/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 404249792.0000 - val_loss: 869103488.0000\n",
      "Epoch 703/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 414298752.0000 - val_loss: 963585600.0000\n",
      "Epoch 704/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 425245536.0000 - val_loss: 815623808.0000\n",
      "Epoch 705/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 433402048.0000 - val_loss: 885552192.0000\n",
      "Epoch 706/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 413196416.0000 - val_loss: 829347648.0000\n",
      "Epoch 707/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 409272512.0000 - val_loss: 865728128.0000\n",
      "Epoch 708/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 404130400.0000 - val_loss: 825554560.0000\n",
      "Epoch 709/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 398387616.0000 - val_loss: 820946880.0000\n",
      "Epoch 710/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408957824.0000 - val_loss: 802502784.0000\n",
      "Epoch 711/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 418469664.0000 - val_loss: 832441408.0000\n",
      "Epoch 712/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 418158144.0000 - val_loss: 814266304.0000\n",
      "Epoch 713/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 439310304.0000 - val_loss: 890508800.0000\n",
      "Epoch 714/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 439641184.0000 - val_loss: 861044736.0000\n",
      "Epoch 715/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 414741792.0000 - val_loss: 917397504.0000\n",
      "Epoch 716/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 421737888.0000 - val_loss: 845553152.0000\n",
      "Epoch 717/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408326496.0000 - val_loss: 932386112.0000\n",
      "Epoch 718/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 413205440.0000 - val_loss: 833607808.0000\n",
      "Epoch 719/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 457609408.0000 - val_loss: 871646976.0000\n",
      "Epoch 720/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 406709440.0000 - val_loss: 819033152.0000\n",
      "Epoch 721/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408061984.0000 - val_loss: 819336832.0000\n",
      "Epoch 722/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 399338336.0000 - val_loss: 958319232.0000\n",
      "Epoch 723/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 409637376.0000 - val_loss: 829738944.0000\n",
      "Epoch 724/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 404785312.0000 - val_loss: 829854592.0000\n",
      "Epoch 725/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 401402944.0000 - val_loss: 888665024.0000\n",
      "Epoch 726/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 409075648.0000 - val_loss: 879856512.0000\n",
      "Epoch 727/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 417671616.0000 - val_loss: 803868480.0000\n",
      "Epoch 728/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 498687872.0000 - val_loss: 851856768.0000\n",
      "Epoch 729/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 454896736.0000 - val_loss: 920454784.0000\n",
      "Epoch 730/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 406777056.0000 - val_loss: 809699584.0000\n",
      "Epoch 731/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 420071808.0000 - val_loss: 852114240.0000\n",
      "Epoch 732/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 456886304.0000 - val_loss: 920440192.0000\n",
      "Epoch 733/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 395028480.0000 - val_loss: 899606528.0000\n",
      "Epoch 734/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 401993600.0000 - val_loss: 824702080.0000\n",
      "Epoch 735/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 441882816.0000 - val_loss: 850991744.0000\n",
      "Epoch 736/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408387840.0000 - val_loss: 839878272.0000\n",
      "Epoch 737/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 407515680.0000 - val_loss: 992299072.0000\n",
      "Epoch 738/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 426831584.0000 - val_loss: 831820608.0000\n",
      "Epoch 739/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 420813280.0000 - val_loss: 969367232.0000\n",
      "Epoch 740/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 414164928.0000 - val_loss: 855432064.0000\n",
      "Epoch 741/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 396729792.0000 - val_loss: 909367104.0000\n",
      "Epoch 742/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 420540512.0000 - val_loss: 912485248.0000\n",
      "Epoch 743/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 396967168.0000 - val_loss: 850861760.0000\n",
      "Epoch 744/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 412891360.0000 - val_loss: 866305536.0000\n",
      "Epoch 745/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 397735392.0000 - val_loss: 840397824.0000\n",
      "Epoch 746/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 414889376.0000 - val_loss: 926810048.0000\n",
      "Epoch 747/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 393942208.0000 - val_loss: 820943744.0000\n",
      "Epoch 748/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 393156160.0000 - val_loss: 840136320.0000\n",
      "Epoch 749/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 377511968.0000 - val_loss: 807939904.0000\n",
      "Epoch 750/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 401327552.0000 - val_loss: 901734976.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 421971008.0000 - val_loss: 820988416.0000\n",
      "Epoch 752/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 414542976.0000 - val_loss: 814099904.0000\n",
      "Epoch 753/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 391585600.0000 - val_loss: 932485440.0000\n",
      "Epoch 754/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 422601472.0000 - val_loss: 809494272.0000\n",
      "Epoch 755/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 401800256.0000 - val_loss: 1015547520.0000\n",
      "Epoch 756/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 476915392.0000 - val_loss: 847565056.0000\n",
      "Epoch 757/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 406223456.0000 - val_loss: 961725632.0000\n",
      "Epoch 758/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 390975712.0000 - val_loss: 881900352.0000\n",
      "Epoch 759/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 388759840.0000 - val_loss: 906012864.0000\n",
      "Epoch 760/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 401990080.0000 - val_loss: 823983360.0000\n",
      "Epoch 761/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 442033184.0000 - val_loss: 891342144.0000\n",
      "Epoch 762/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 385906656.0000 - val_loss: 826745728.0000\n",
      "Epoch 763/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 381898688.0000 - val_loss: 874606336.0000\n",
      "Epoch 764/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 386391008.0000 - val_loss: 833565824.0000\n",
      "Epoch 765/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 423916608.0000 - val_loss: 875574976.0000\n",
      "Epoch 766/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 386983456.0000 - val_loss: 846949312.0000\n",
      "Epoch 767/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 381565408.0000 - val_loss: 816986112.0000\n",
      "Epoch 768/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 401182080.0000 - val_loss: 976681792.0000\n",
      "Epoch 769/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 531017216.0000 - val_loss: 900936896.0000\n",
      "Epoch 770/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 378050400.0000 - val_loss: 820209024.0000\n",
      "Epoch 771/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 402325888.0000 - val_loss: 815782272.0000\n",
      "Epoch 772/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 377642432.0000 - val_loss: 822087424.0000\n",
      "Epoch 773/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 381471968.0000 - val_loss: 805841024.0000\n",
      "Epoch 774/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 397008032.0000 - val_loss: 900460480.0000\n",
      "Epoch 775/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 391264544.0000 - val_loss: 823808704.0000\n",
      "Epoch 776/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 395348960.0000 - val_loss: 831206784.0000\n",
      "Epoch 777/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 374587936.0000 - val_loss: 840491072.0000\n",
      "Epoch 778/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 385196096.0000 - val_loss: 1139526912.0000\n",
      "Epoch 779/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 417496576.0000 - val_loss: 856095872.0000\n",
      "Epoch 780/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 374003488.0000 - val_loss: 827226752.0000\n",
      "Epoch 781/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 366880352.0000 - val_loss: 828085696.0000\n",
      "Epoch 782/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 381661632.0000 - val_loss: 932276096.0000\n",
      "Epoch 783/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 382376064.0000 - val_loss: 832542336.0000\n",
      "Epoch 784/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 399790016.0000 - val_loss: 839897344.0000\n",
      "Epoch 785/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 418903520.0000 - val_loss: 1029346688.0000\n",
      "Epoch 786/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 385251904.0000 - val_loss: 821692800.0000\n",
      "Epoch 787/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 370829344.0000 - val_loss: 921446336.0000\n",
      "Epoch 788/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 416474784.0000 - val_loss: 1048479936.0000\n",
      "Epoch 789/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 410170208.0000 - val_loss: 798484352.0000\n",
      "Epoch 790/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 367935648.0000 - val_loss: 832416192.0000\n",
      "Epoch 791/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375128224.0000 - val_loss: 827045824.0000\n",
      "Epoch 792/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375324640.0000 - val_loss: 833085952.0000\n",
      "Epoch 793/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375858560.0000 - val_loss: 880515520.0000\n",
      "Epoch 794/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 386056224.0000 - val_loss: 888586560.0000\n",
      "Epoch 795/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 374315968.0000 - val_loss: 829613888.0000\n",
      "Epoch 796/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 402872864.0000 - val_loss: 956130304.0000\n",
      "Epoch 797/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 381367552.0000 - val_loss: 826209152.0000\n",
      "Epoch 798/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 361679744.0000 - val_loss: 828331136.0000\n",
      "Epoch 799/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 366976672.0000 - val_loss: 820380416.0000\n",
      "Epoch 800/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 367485024.0000 - val_loss: 850052736.0000\n",
      "Epoch 801/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 360564000.0000 - val_loss: 834259136.0000\n",
      "Epoch 802/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 381275648.0000 - val_loss: 1029121216.0000\n",
      "Epoch 803/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 427582400.0000 - val_loss: 839695424.0000\n",
      "Epoch 804/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 379460416.0000 - val_loss: 841926976.0000\n",
      "Epoch 805/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 381010816.0000 - val_loss: 812369792.0000\n",
      "Epoch 806/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 405426400.0000 - val_loss: 965526656.0000\n",
      "Epoch 807/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 377428480.0000 - val_loss: 836077824.0000\n",
      "Epoch 808/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 396321024.0000 - val_loss: 836517248.0000\n",
      "Epoch 809/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 403602016.0000 - val_loss: 885285824.0000\n",
      "Epoch 810/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 370080864.0000 - val_loss: 821791616.0000\n",
      "Epoch 811/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 386973056.0000 - val_loss: 892575168.0000\n",
      "Epoch 812/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375784064.0000 - val_loss: 875197568.0000\n",
      "Epoch 813/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 368174208.0000 - val_loss: 835297536.0000\n",
      "Epoch 814/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 390838944.0000 - val_loss: 1013032576.0000\n",
      "Epoch 815/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 453528224.0000 - val_loss: 897677440.0000\n",
      "Epoch 816/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 376790816.0000 - val_loss: 843304128.0000\n",
      "Epoch 817/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 408344832.0000 - val_loss: 959447488.0000\n",
      "Epoch 818/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 433070016.0000 - val_loss: 855944704.0000\n",
      "Epoch 819/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 467921344.0000 - val_loss: 824822592.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 468898944.0000 - val_loss: 999946368.0000\n",
      "Epoch 821/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 393627008.0000 - val_loss: 842721152.0000\n",
      "Epoch 822/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 367703648.0000 - val_loss: 869220736.0000\n",
      "Epoch 823/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 364812512.0000 - val_loss: 839014592.0000\n",
      "Epoch 824/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 401801024.0000 - val_loss: 826841984.0000\n",
      "Epoch 825/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 386071648.0000 - val_loss: 849056576.0000\n",
      "Epoch 826/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 359490656.0000 - val_loss: 860570048.0000\n",
      "Epoch 827/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 349447584.0000 - val_loss: 826987264.0000\n",
      "Epoch 828/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 364105984.0000 - val_loss: 956167104.0000\n",
      "Epoch 829/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 401485728.0000 - val_loss: 903100480.0000\n",
      "Epoch 830/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 444930624.0000 - val_loss: 847453632.0000\n",
      "Epoch 831/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 404402016.0000 - val_loss: 868559744.0000\n",
      "Epoch 832/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 353853696.0000 - val_loss: 862160448.0000\n",
      "Epoch 833/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 375537536.0000 - val_loss: 883601536.0000\n",
      "Epoch 834/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 385824512.0000 - val_loss: 835641472.0000\n",
      "Epoch 835/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 377312672.0000 - val_loss: 837411776.0000\n",
      "Epoch 836/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 350328320.0000 - val_loss: 1029209856.0000\n",
      "Epoch 837/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 385705088.0000 - val_loss: 856655104.0000\n",
      "Epoch 838/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 351543872.0000 - val_loss: 882827968.0000\n",
      "Epoch 839/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 347961280.0000 - val_loss: 863254912.0000\n",
      "Epoch 840/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 362601792.0000 - val_loss: 860422016.0000\n",
      "Epoch 841/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 392680288.0000 - val_loss: 960621760.0000\n",
      "Epoch 842/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 383452864.0000 - val_loss: 877710592.0000\n",
      "Epoch 843/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 350091680.0000 - val_loss: 867794240.0000\n",
      "Epoch 844/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 355345184.0000 - val_loss: 895288448.0000\n",
      "Epoch 845/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 345856704.0000 - val_loss: 918693440.0000\n",
      "Epoch 846/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 346711712.0000 - val_loss: 836961920.0000\n",
      "Epoch 847/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 407850880.0000 - val_loss: 852461312.0000\n",
      "Epoch 848/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 369469984.0000 - val_loss: 810319872.0000\n",
      "Epoch 849/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 364779200.0000 - val_loss: 830307584.0000\n",
      "Epoch 850/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 385198880.0000 - val_loss: 850164800.0000\n",
      "Epoch 851/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 347738560.0000 - val_loss: 863062336.0000\n",
      "Epoch 852/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 351465120.0000 - val_loss: 900432128.0000\n",
      "Epoch 853/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 376054336.0000 - val_loss: 816021248.0000\n",
      "Epoch 854/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 351567968.0000 - val_loss: 832883328.0000\n",
      "Epoch 855/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 345127776.0000 - val_loss: 840648192.0000\n",
      "Epoch 856/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 407913088.0000 - val_loss: 840146624.0000\n",
      "Epoch 857/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 371669344.0000 - val_loss: 894702400.0000\n",
      "Epoch 858/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 384643424.0000 - val_loss: 884759232.0000\n",
      "Epoch 859/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 361168288.0000 - val_loss: 826217536.0000\n",
      "Epoch 860/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 420184128.0000 - val_loss: 835622592.0000\n",
      "Epoch 861/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 367129088.0000 - val_loss: 841944192.0000\n",
      "Epoch 862/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 356656736.0000 - val_loss: 944811648.0000\n",
      "Epoch 863/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 347258944.0000 - val_loss: 837424896.0000\n",
      "Epoch 864/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 341076928.0000 - val_loss: 873165312.0000\n",
      "Epoch 865/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 346754560.0000 - val_loss: 917605376.0000\n",
      "Epoch 866/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 359881632.0000 - val_loss: 831778432.0000\n",
      "Epoch 867/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 355596384.0000 - val_loss: 834690176.0000\n",
      "Epoch 868/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 353066688.0000 - val_loss: 850006848.0000\n",
      "Epoch 869/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 351440896.0000 - val_loss: 819763008.0000\n",
      "Epoch 870/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 356067872.0000 - val_loss: 897404480.0000\n",
      "Epoch 871/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 353046336.0000 - val_loss: 849041856.0000\n",
      "Epoch 872/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 355609600.0000 - val_loss: 878156160.0000\n",
      "Epoch 873/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 351509280.0000 - val_loss: 856510208.0000\n",
      "Epoch 874/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 338919744.0000 - val_loss: 820880256.0000\n",
      "Epoch 875/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 338725536.0000 - val_loss: 933407104.0000\n",
      "Epoch 876/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 349393952.0000 - val_loss: 899054144.0000\n",
      "Epoch 877/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 340815232.0000 - val_loss: 827261056.0000\n",
      "Epoch 878/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 343332480.0000 - val_loss: 900670784.0000\n",
      "Epoch 879/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 397017440.0000 - val_loss: 813920192.0000\n",
      "Epoch 880/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 414317376.0000 - val_loss: 853603008.0000\n",
      "Epoch 881/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 374936032.0000 - val_loss: 884782912.0000\n",
      "Epoch 882/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 343738624.0000 - val_loss: 863160320.0000\n",
      "Epoch 883/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 342940512.0000 - val_loss: 901849856.0000\n",
      "Epoch 884/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 345475328.0000 - val_loss: 1010793152.0000\n",
      "Epoch 885/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 348686944.0000 - val_loss: 868644032.0000\n",
      "Epoch 886/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 340285888.0000 - val_loss: 839620544.0000\n",
      "Epoch 887/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 336091712.0000 - val_loss: 844151232.0000\n",
      "Epoch 888/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 341775712.0000 - val_loss: 838358400.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 889/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 364460000.0000 - val_loss: 842671424.0000\n",
      "Epoch 890/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 366850112.0000 - val_loss: 863514368.0000\n",
      "Epoch 891/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 353449248.0000 - val_loss: 900431872.0000\n",
      "Epoch 892/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 387295936.0000 - val_loss: 828886208.0000\n",
      "Epoch 893/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 390830592.0000 - val_loss: 866301120.0000\n",
      "Epoch 894/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 380700576.0000 - val_loss: 835318272.0000\n",
      "Epoch 895/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 378542144.0000 - val_loss: 860745984.0000\n",
      "Epoch 896/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 350275776.0000 - val_loss: 851908608.0000\n",
      "Epoch 897/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 328422848.0000 - val_loss: 976658752.0000\n",
      "Epoch 898/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 373102816.0000 - val_loss: 840632192.0000\n",
      "Epoch 899/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375003936.0000 - val_loss: 855926336.0000\n",
      "Epoch 900/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 384792544.0000 - val_loss: 837690688.0000\n",
      "Epoch 901/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 350707936.0000 - val_loss: 949762048.0000\n",
      "Epoch 902/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 332022400.0000 - val_loss: 905103872.0000\n",
      "Epoch 903/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 336175872.0000 - val_loss: 842646080.0000\n",
      "Epoch 904/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 339351712.0000 - val_loss: 1004050112.0000\n",
      "Epoch 905/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 336322144.0000 - val_loss: 844891776.0000\n",
      "Epoch 906/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 338257664.0000 - val_loss: 845581248.0000\n",
      "Epoch 907/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 361050528.0000 - val_loss: 844690560.0000\n",
      "Epoch 908/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 333159136.0000 - val_loss: 858423936.0000\n",
      "Epoch 909/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 331595616.0000 - val_loss: 847513728.0000\n",
      "Epoch 910/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 339031904.0000 - val_loss: 847756864.0000\n",
      "Epoch 911/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 327470048.0000 - val_loss: 840253760.0000\n",
      "Epoch 912/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 335029760.0000 - val_loss: 847167040.0000\n",
      "Epoch 913/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 363527552.0000 - val_loss: 1008973312.0000\n",
      "Epoch 914/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 333480000.0000 - val_loss: 833313856.0000\n",
      "Epoch 915/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 345857376.0000 - val_loss: 1089068672.0000\n",
      "Epoch 916/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 375772352.0000 - val_loss: 837652864.0000\n",
      "Epoch 917/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 336373408.0000 - val_loss: 878395712.0000\n",
      "Epoch 918/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 335342560.0000 - val_loss: 838304448.0000\n",
      "Epoch 919/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 322333792.0000 - val_loss: 836772544.0000\n",
      "Epoch 920/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 329473120.0000 - val_loss: 847747328.0000\n",
      "Epoch 921/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 338447200.0000 - val_loss: 939434304.0000\n",
      "Epoch 922/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 321566432.0000 - val_loss: 898595264.0000\n",
      "Epoch 923/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 413154272.0000 - val_loss: 862085376.0000\n",
      "Epoch 924/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 377711168.0000 - val_loss: 1072381376.0000\n",
      "Epoch 925/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 371606336.0000 - val_loss: 940506176.0000\n",
      "Epoch 926/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 345744704.0000 - val_loss: 972147584.0000\n",
      "Epoch 927/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 328493152.0000 - val_loss: 862970048.0000\n",
      "Epoch 928/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 325555520.0000 - val_loss: 858451712.0000\n",
      "Epoch 929/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 378606528.0000 - val_loss: 849315392.0000\n",
      "Epoch 930/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 341628064.0000 - val_loss: 873403264.0000\n",
      "Epoch 931/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 352464832.0000 - val_loss: 903900672.0000\n",
      "Epoch 932/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 333208064.0000 - val_loss: 910558080.0000\n",
      "Epoch 933/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 367315296.0000 - val_loss: 906015360.0000\n",
      "Epoch 934/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 325516640.0000 - val_loss: 846435840.0000\n",
      "Epoch 935/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 329621664.0000 - val_loss: 849754752.0000\n",
      "Epoch 936/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 334439520.0000 - val_loss: 837454464.0000\n",
      "Epoch 937/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 332807424.0000 - val_loss: 828283456.0000\n",
      "Epoch 938/1000\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 319111008.0000 - val_loss: 956559168.0000\n",
      "Epoch 939/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 339668128.0000 - val_loss: 884520960.0000\n",
      "Epoch 940/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 337842912.0000 - val_loss: 896607872.0000\n",
      "Epoch 941/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 312876704.0000 - val_loss: 877805440.0000\n",
      "Epoch 942/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 341170720.0000 - val_loss: 953518720.0000\n",
      "Epoch 943/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 433733856.0000 - val_loss: 834977472.0000\n",
      "Epoch 944/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 361931488.0000 - val_loss: 848436544.0000\n",
      "Epoch 945/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 332587744.0000 - val_loss: 877632320.0000\n",
      "Epoch 946/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 323259296.0000 - val_loss: 848800192.0000\n",
      "Epoch 947/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 323297024.0000 - val_loss: 892923968.0000\n",
      "Epoch 948/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 329768672.0000 - val_loss: 1179454080.0000\n",
      "Epoch 949/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 366532832.0000 - val_loss: 852582720.0000\n",
      "Epoch 950/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 324260512.0000 - val_loss: 851846528.0000\n",
      "Epoch 951/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 344735872.0000 - val_loss: 877961408.0000\n",
      "Epoch 952/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 365084832.0000 - val_loss: 919091200.0000\n",
      "Epoch 953/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 349818944.0000 - val_loss: 1084287744.0000\n",
      "Epoch 954/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 367702304.0000 - val_loss: 840864576.0000\n",
      "Epoch 955/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 386396928.0000 - val_loss: 831759680.0000\n",
      "Epoch 956/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 344640096.0000 - val_loss: 930390720.0000\n",
      "Epoch 957/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 317905824.0000 - val_loss: 872319616.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 958/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 333869184.0000 - val_loss: 857735104.0000\n",
      "Epoch 959/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 336171104.0000 - val_loss: 860167232.0000\n",
      "Epoch 960/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 349584800.0000 - val_loss: 854200832.0000\n",
      "Epoch 961/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 354773792.0000 - val_loss: 861179648.0000\n",
      "Epoch 962/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 331316544.0000 - val_loss: 912998528.0000\n",
      "Epoch 963/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 333705824.0000 - val_loss: 884380288.0000\n",
      "Epoch 964/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 321300576.0000 - val_loss: 865538240.0000\n",
      "Epoch 965/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 331252288.0000 - val_loss: 858713792.0000\n",
      "Epoch 966/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 339684448.0000 - val_loss: 1043067520.0000\n",
      "Epoch 967/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 338184352.0000 - val_loss: 918354944.0000\n",
      "Epoch 968/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 319166720.0000 - val_loss: 916071168.0000\n",
      "Epoch 969/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 380558240.0000 - val_loss: 883987840.0000\n",
      "Epoch 970/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 373666272.0000 - val_loss: 891071360.0000\n",
      "Epoch 971/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 324836064.0000 - val_loss: 944446912.0000\n",
      "Epoch 972/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 389606208.0000 - val_loss: 912026048.0000\n",
      "Epoch 973/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 324934656.0000 - val_loss: 938116800.0000\n",
      "Epoch 974/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 335634880.0000 - val_loss: 870342208.0000\n",
      "Epoch 975/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 348635200.0000 - val_loss: 871799680.0000\n",
      "Epoch 976/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 357775968.0000 - val_loss: 852378624.0000\n",
      "Epoch 977/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 324467904.0000 - val_loss: 875787136.0000\n",
      "Epoch 978/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 316663904.0000 - val_loss: 911720832.0000\n",
      "Epoch 979/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 316925664.0000 - val_loss: 879132992.0000\n",
      "Epoch 980/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 311781088.0000 - val_loss: 885720704.0000\n",
      "Epoch 981/1000\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 321113440.0000 - val_loss: 856949632.0000\n",
      "Epoch 982/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 314759584.0000 - val_loss: 857485696.0000\n",
      "Epoch 983/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 319446368.0000 - val_loss: 865589952.0000\n",
      "Epoch 984/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 367064032.0000 - val_loss: 854426368.0000\n",
      "Epoch 985/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 318447328.0000 - val_loss: 860741376.0000\n",
      "Epoch 986/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 319896768.0000 - val_loss: 899582400.0000\n",
      "Epoch 987/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 311057536.0000 - val_loss: 943503488.0000\n",
      "Epoch 988/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 307087136.0000 - val_loss: 850124096.0000\n",
      "Epoch 989/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 332275360.0000 - val_loss: 849542464.0000\n",
      "Epoch 990/1000\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 325487136.0000 - val_loss: 963115584.0000\n",
      "Epoch 991/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 329684960.0000 - val_loss: 872539008.0000\n",
      "Epoch 992/1000\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 325083424.0000 - val_loss: 840981760.0000\n",
      "Epoch 993/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 337777600.0000 - val_loss: 922152064.0000\n",
      "Epoch 994/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 327876544.0000 - val_loss: 836421696.0000\n",
      "Epoch 995/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 302880288.0000 - val_loss: 930796032.0000\n",
      "Epoch 996/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 310242048.0000 - val_loss: 855258176.0000\n",
      "Epoch 997/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 330025344.0000 - val_loss: 882778432.0000\n",
      "Epoch 998/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 362385088.0000 - val_loss: 841223808.0000\n",
      "Epoch 999/1000\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 323964192.0000 - val_loss: 844768576.0000\n",
      "Epoch 1000/1000\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 320903072.0000 - val_loss: 901489344.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26a397ddf40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,output,validation_split=0.1,\n",
    "          batch_size=64,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0361890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 6s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>206329.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>178674.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>214343.109375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151406.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>291295.093750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      SalePrice\n",
       "0   1  206329.218750\n",
       "1   2  178674.093750\n",
       "2   3  214343.109375\n",
       "3   4  151406.062500\n",
       "4   5  291295.093750"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(train) # Prediction using model\n",
    "result = pd.DataFrame(result,columns=['SalePrice']) # Dataframe\n",
    "result['Id'] = df_pricing['Id'] # Adding ID to our result dataframe.\n",
    "result = result[['Id','SalePrice']]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dff7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"orginal_price\"] = df_pricing['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7284818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>orginal_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>206329.218750</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>178674.093750</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>214343.109375</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151406.062500</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>291295.093750</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id      SalePrice  orginal_price\n",
       "0   1  206329.218750         208500\n",
       "1   2  178674.093750         181500\n",
       "2   3  214343.109375         223500\n",
       "3   4  151406.062500         140000\n",
       "4   5  291295.093750         250000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a58cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>127391.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>178344.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>198116.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>182730.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>175181.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id      SalePrice\n",
       "0  1461  127391.804688\n",
       "1  1462  178344.812500\n",
       "2  1463  198116.906250\n",
       "3  1464  182730.156250\n",
       "4  1465  175181.906250"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.predict(test) # Prediction using model\n",
    "result = pd.DataFrame(result,columns=['SalePrice']) # Dataframe\n",
    "result['Id'] = df_pricing_test['Id'] # Adding ID to our result dataframe.\n",
    "result = result[['Id','SalePrice']]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee1aa3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('house_prices_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353821e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
